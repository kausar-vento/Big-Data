<center><h1>Tugas Pratikum  2</h1></center>
<ul>
  <p>Kode 1: sc, accumulator, parallelize, lambda, value</p>
  <ul>
    <li>SC: adalah variabel yang digunakan untuk SparkContext di PySpark. SparkContext adalah objek inti untuk koneksi ke kluster Spark dan membuat RDD.</li>
    <li>Accumulator: adalah variabel yang digunakan untuk mengumpulkan nilai di seluruh kluster dalam mode read-only atau read-write.</li>
    <li>Parallelize: dalah fungsi yang digunakan untuk mengubah koleksi Python menjadi RDD. Ini membagi koleksi menjadi bagian-bagian dan mendistribusikan bagian-bagian tersebut di seluruh node dalam kluster.</li>
    <li>Lambda: adalah fungsi anonim di Python. Fungsi ini dapat digunakan untuk membuat fungsi sederhana yang hanya membutuhkan satu argumen. lambda biasanya digunakan dalam PySpark untuk mengubah nilai pada RDD</li>
    <li>Value: adalah variabel yang digunakan untuk menyimpan nilai yang bersifat tidak berubah pada PySpark</li>
  </ul>
  <p>Kode 2: broadcast, list, range</p>
  <p>Kode 3: textFile, filter, cache, count</p>
  <p>Kode 4: map, collect, len, keys, values</p>
  <p>Kode 5: defaultParallelism, getNumPartitions, mapPartitionsWithIndex, repartition, coalesce, toDebugString</p>
  <p>Kode 6: flatMap, reduceByKey, split</p>
</ul>
